{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhqXxpamFARq"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi # Check whether your system has a GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTN7o73CxpU0"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NoduTJIqEvv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import torch \n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_ycU-vBtaCv"
      },
      "source": [
        "numpy \n",
        "- A scientific computing library\n",
        "- Supports array operations and manipulations\n",
        "- Built-in functions like array sum, diff, mean, average, min, max etc.\n",
        "\n",
        "cv2\n",
        "- To read and write images\n",
        "- To perform basic vision algorithms like RGB to HSV, Gaussian Blur, Dilation, Histogram, Shape detection etc.\n",
        "\n",
        "torch\n",
        "- The open source ML framework for deep learning\n",
        "- Has a pythonic interface\n",
        "\n",
        "torchvision\n",
        "- consists of popular datasets, model architectures, and common image transformations for computer vision\n",
        "- Contains built in data augmentations\n",
        "\n",
        "matplotlib\n",
        "- It is a data visualization library for python\n",
        "- It supports graphical plotting and viewing images and other data\n",
        "\n",
        "nn\n",
        "- The base module with which we can create and train neural nets\n",
        "- Provides built-in classes for common neural network layers like Conv, Pooling, Activations, Normalizations, Dropout etc.\n",
        "\n",
        "optim\n",
        "- It is a package for implementing various optimization algorithms for model training\n",
        "- Built-in optimizers like SGD, Adam, Adagrad, RMSprop etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8Qbwuzdx0dH"
      },
      "source": [
        "# Preprocess inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVcCk-6TyvEy"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()]) # Define the set of transformations to be applied on the input data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lFD-xj8qWVc"
      },
      "outputs": [],
      "source": [
        "# transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,)),])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xeJCeo3yE9Z"
      },
      "source": [
        "ToTensor()\n",
        " - converts the image with a pixel range of [0, 255] to a PyTorch FloatTensor of shape (C, H, W) with a range [0.0, 1.0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uzgtjA4xCnv"
      },
      "source": [
        "Normalize() \n",
        "- output[channel] = (input[channel] - mean[channel]) / std[channel]\n",
        "\n",
        "- Normalization helps get data within a range and reduces the skewness which helps learn faster and better. \n",
        "- Normalization can also tackle the diminishing and exploding gradients problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dZes3DQzlsm"
      },
      "source": [
        "# Create Dataloaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_oL6gEw01fO"
      },
      "source": [
        "- Combines a dataset and a sampler\n",
        "- Provides an iterable over the given dataset\n",
        "- Supports single- or multi-process loading\n",
        "- Customizing loading order\n",
        "- Automatic batching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1AcwXIMqY7w"
      },
      "outputs": [],
      "source": [
        "trainset = datasets.CIFAR10('trainset', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-258nSWz5i9"
      },
      "outputs": [],
      "source": [
        "valset = datasets.CIFAR10('testset', download=True, train=False, transform=transform)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDZYc7_xz-tM"
      },
      "outputs": [],
      "source": [
        "dataiter = iter(trainloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Cxx5qFSCMdl"
      },
      "source": [
        "Now that we have an iterator, let's visualize our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9Qg2ipB0Acv"
      },
      "outputs": [],
      "source": [
        "images, gt_labels = dataiter.next() # The first minibatch of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVoe0YEL0Dtu"
      },
      "outputs": [],
      "source": [
        "print(images.shape)\n",
        "print(gt_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTOnzN15uaN8"
      },
      "outputs": [],
      "source": [
        " # Visualize an image sample\n",
        "plt.imshow((images[2].squeeze()).permute(1,2,0).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBvtMO96ud6w"
      },
      "outputs": [],
      "source": [
        "# Visualize all images in the minibatch\n",
        "figure = plt.figure()\n",
        "total_samples = 8\n",
        "for index in range(1,total_samples+1):\n",
        "    ax = plt.subplot(2, 4, index)\n",
        "    ax.set_xlabel(classes[gt_labels[index-1].item()])\n",
        "    # plt.axis('off')\n",
        "    plt.imshow(images[index-1].squeeze().permute(1,2,0).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9u1I-5qDGiQV"
      },
      "outputs": [],
      "source": [
        "# Visualize the Ground truth labels\n",
        "print(gt_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qr_TSdxjGo5k"
      },
      "outputs": [],
      "source": [
        "# Visualize the onehot encoding of the labels\n",
        "onehot_labels = nn.functional.one_hot(gt_labels, num_classes=10)\n",
        "print(onehot_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a Model for CIFAR-10 Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CIFARModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIT4IGppv_ql"
      },
      "outputs": [],
      "source": [
        "model = CIFARModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujZRzrUDu2yp"
      },
      "outputs": [],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtHlwTqkxNPX"
      },
      "source": [
        "Visualize the probabilities of a sample image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJBGGVn2HZPF"
      },
      "outputs": [],
      "source": [
        "# see a sample image\n",
        "plt.imshow(images[0].squeeze().permute(1,2,0).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7Rq1b7CFffH"
      },
      "outputs": [],
      "source": [
        "# print the ground truth label\n",
        "print(gt_labels[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3Y6AxlxHFZ3"
      },
      "outputs": [],
      "source": [
        "# print the ground truth onehot representation\n",
        "print(onehot_labels[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvGewAkurCO8"
      },
      "source": [
        "# Better Training Loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTWhclb4ty0h"
      },
      "source": [
        "- Add a progress bar for the training\n",
        "- After each epoch, validate the model to see if the model has converged or whether it is overfit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOoU9_GirIE2"
      },
      "outputs": [],
      "source": [
        "model = CIFARModel().cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "epochs = 100\n",
        "pbar = tqdm(range(epochs))\n",
        "best_accuracy = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDSSSZJQrQc8"
      },
      "outputs": [],
      "source": [
        "time_init = time() # record the time at which training started\n",
        "\n",
        "for e in pbar:\n",
        "    running_loss = 0\n",
        "    for images, gt_labels in tqdm(trainloader):\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.cuda()\n",
        "        gt_labels = gt_labels.cuda()\n",
        "    \n",
        "        # Training pass\n",
        "        optimizer.zero_grad() # reset the gradients of model weights\n",
        "        \n",
        "        output = model(images)\n",
        "        loss = criterion(output, gt_labels)\n",
        "        \n",
        "        # Calculate the gradients of the learnable parameters\n",
        "        loss.backward()\n",
        "        \n",
        "        # Modify the model weights as per the gradients\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    average_loss = running_loss/len(trainloader)\n",
        "    \n",
        "    # perform validation\n",
        "    correct_count = 0\n",
        "    total_count = 0\n",
        "    for images,gt_labels in valloader:\n",
        "      pred_probs = model(images.cuda())\n",
        "      predicted_labels = torch.argmax(pred_probs, dim=-1)\n",
        "\n",
        "      for i in range(len(gt_labels)):\n",
        "        if predicted_labels[i]==gt_labels[i]:\n",
        "          correct_count = correct_count+1\n",
        "        total_count = total_count+1       \n",
        "\n",
        "    accuracy = correct_count/total_count\n",
        "    \n",
        "    # save the model weights\n",
        "    if accuracy>=best_accuracy:\n",
        "      best_accuracy = accuracy\n",
        "      torch.save(model, './best_cifar_model.pt')\n",
        "    torch.save(model, './last_cifar_model.pt') \n",
        "\n",
        "    print(f\"\\nEpoch {e} - Training loss: {average_loss}, val accuracy : {accuracy}\")\n",
        "print(f\"Training Time (in minutes) = {(time()-time_init)/60}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "images, gt_labels = next(iter(valloader))\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred_probs = model(images.cuda())\n",
        "\n",
        "predicted_labels = torch.argmax(pred_probs, dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lets visualize the validation input images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize all images in the minibatch\n",
        "figure = plt.figure()\n",
        "total_samples = 8\n",
        "for index in range(1,total_samples+1):\n",
        "    ax = plt.subplot(2, 4, index)\n",
        "    ax.set_xlabel(classes[gt_labels[index-1].item()])\n",
        "    # plt.axis('off')\n",
        "    plt.imshow(images[index-1].squeeze().permute(1,2,0).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iuw_0SKgTq3o"
      },
      "source": [
        "Ground truth class labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfGjJk_Ga4Uz"
      },
      "outputs": [],
      "source": [
        "print(f\"Ground truth labels : {gt_labels}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EhHsTcoT5Lg"
      },
      "source": [
        "Predicted class labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsrexeF1bUJH"
      },
      "outputs": [],
      "source": [
        "print(f\"Predicted labels : {predicted_labels}\",)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize all images in the minibatch\n",
        "figure = plt.figure()\n",
        "total_samples = 8\n",
        "for index in range(1,total_samples+1):\n",
        "    ax = plt.subplot(2, 4, index)\n",
        "    ax.set_xlabel(classes[predicted_labels[index-1].item()])\n",
        "    # plt.axis('off')\n",
        "    plt.imshow(images[index-1].squeeze().permute(1,2,0).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HglyDz4SDuDx"
      },
      "outputs": [],
      "source": [
        "correct_count = 0\n",
        "total_count = 0\n",
        "for i in range(len(gt_labels)):\n",
        "  img = images[i]\n",
        "  if predicted_labels[i]==gt_labels[i]:\n",
        "    correct_count = correct_count+1\n",
        "  total_count = total_count+1\n",
        "accuracy = correct_count/total_count\n",
        "print(f\"The accuracy on the minibatch is : {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8USdqKtnMKo"
      },
      "outputs": [],
      "source": [
        "correct_count = 0\n",
        "total_count = 0\n",
        "\n",
        "for images,gt_labels in valloader:\n",
        "  pred_probs = model(images.cuda())\n",
        "  predicted_labels = torch.argmax(pred_probs, dim=-1)\n",
        "\n",
        "  for i in range(len(gt_labels)):\n",
        "    if predicted_labels[i]==gt_labels[i]:\n",
        "      correct_count = correct_count+1\n",
        "    total_count = total_count+1       \n",
        "\n",
        "accuracy = correct_count/total_count\n",
        "print(f\"Number of validation images = {total_count}\\n\")\n",
        "print(f\"Model Accuracy = {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "wCn3pKjc_iTF",
        "NfSyK7w6_7Ba",
        "VFOu2DDNPAju",
        "GgZgs_bPQMwg"
      ],
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.13 ('torchenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0c9fb112d4624b5e4fa7b873160be5d487c9f44e6948be985e0928a4033755e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
